{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cca8506-7a6b-4568-a5cc-ee51b7d97ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): error when deleting \"g2gt.yaml\": jobs.batch \"g2gt-gen\" not found\n",
      "job.batch/g2gt-gen created\n"
     ]
    }
   ],
   "source": [
    "! kubectl delete -f g2gt.yaml\n",
    "! kubectl apply -f g2gt.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f26447-2d20-4850-93a4-f33aacb96f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job.batch \"g2gt-gen\" deleted\n"
     ]
    }
   ],
   "source": [
    "! kubectl delete -f g2gt.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4f7f28-01b8-4839-baa5-eeee27aec3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: error parsing g2gt-ddp.yaml: error converting YAML to JSON: yaml: line 31: did not find expected key\n",
      "error: error parsing g2gt-ddp.yaml: error converting YAML to JSON: yaml: line 31: did not find expected key\n"
     ]
    }
   ],
   "source": [
    "! kubectl delete -f g2gt-ddp.yaml\n",
    "! kubectl apply -f g2gt-ddp.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6bf1f44-8a67-4a94-b138-8a281aba49af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): pytorchjobs.kubeflow.org \"g2gt-ddp\" not found\n"
     ]
    }
   ],
   "source": [
    "! kubectl delete -n linzaiyun g2gt-ddp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aac3bd41-f0da-4c6e-abc7-27d55a4fe413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorchjob.kubeflow.org \"ddp-test\" deleted\n",
      "pytorchjob.kubeflow.org/ddp-test created\n"
     ]
    }
   ],
   "source": [
    "! kubectl delete -f ranzcr.yaml\n",
    "! kubectl apply -f ranzcr.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2834524-541a-41a2-aa09-53d0e207b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.sh: line 5: cd: g2gt_github/src/: No such file or directory\n",
      "\n",
      "\n",
      "\n",
      "=====================================ARGS======================================\n",
      "arg0: train.sh\n",
      "exp_name: uspto\n",
      "arch: --ffn_dim 1024 --hidden_dim 256 --dropout_rate 0.1 --intput_dropout_rate 0.05 --attention_dropout_rate 0.1 --n_layer 6 --peak_lr 2.5e-4 --end_lr 1e-6 --head_size 12 --weight_decay 0.00 --edge_type one_hop --warmup_updates 3000 --tot_updates 700000\n",
      "seed: 0\n",
      "batch_size: 5\n",
      "===============================================================================\n",
      "Namespace(accelerator='ddp', accumulate_grad_batches=1, amp_backend='native', amp_level='O2', attention_dropout_rate=0.1, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch_size=5, beam=1, benchmark=False, check_val_every_n_epoch=1, checkpoint_callback=True, checkpoint_path='', dataset_name='typed_uspto50k_split2', default_root_dir='/home/jovyan/g2gt_github/src', deterministic=False, devices=None, distributed_backend=None, dropout_rate=0.1, edge_type='one_hop', end_lr=1e-06, fast_dev_run=False, ffn_dim=1024, flag=False, flag_m=3, flag_mag=0.001, flag_step_size=0.001, flush_logs_every_n_steps=100, gpus=1, gradient_clip_algorithm='norm', gradient_clip_val=4.0, head_size=12, hidden_dim=256, intput_dropout_rate=0.05, ipus=None, limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, max_epochs=None, max_steps=700001, max_time=None, min_epochs=100, min_steps=None, move_metrics_to_cpu=False, multi_hop_max_dist=5, multiple_trainloader_mode='max_size_cycle', n_layers=6, num_nodes=1, num_processes=1, num_sanity_val_steps=2, num_workers=1, overfit_batches=0.0, peak_lr=0.00025, plugins=<pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7fae848c6a90>, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=10, rel_pos_max=1024, reload_dataloaders_every_epoch=False, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, seed=0, stochastic_weight_avg=False, sync_batchnorm=True, terminate_on_nan=False, test=False, tot_updates=700000, tpu_cores=None, track_grad_norm=-1, truncated_bptt_steps=None, val_check_interval=1000, validate=False, warmup_updates=3000, weight_decay=0.0, weights_save_path=None, weights_summary='top')\n",
      "Global seed set to 0\n",
      " > dataset_name: typed_uspto50k_split2\n",
      " > typed_uspto50k_split2 loaded!\n",
      "{'num_class': 1, 'loss_fn': <function cross_entropy at 0x7faecf4fa050>, 'metric': 'train_loss', 'metric_mode': 'min', 'evaluator': 'none', 'dataset': UsptoDataset(50000), 'max_node': 420}\n",
      " > dataset info ends\n",
      "GraphFormer(\n",
      "  (atom_encoder): Embedding(4737, 256, padding_idx=0)\n",
      "  (edge_encoder): Embedding(769, 12, padding_idx=0)\n",
      "  (rel_pos_encoder): Embedding(512, 12, padding_idx=0)\n",
      "  (in_degree_encoder): Embedding(512, 256, padding_idx=0)\n",
      "  (out_degree_encoder): Embedding(512, 256, padding_idx=0)\n",
      "  (input_dropout): Dropout(p=0.05, inplace=False)\n",
      "  (input_dropout2d): Dropout2d(p=0.05, inplace=False)\n",
      "  (gelu): GELU()\n",
      "  (atom_edge_encoder): Embedding(543, 256, padding_idx=0)\n",
      "  (centrality_encoder): Embedding(50, 12, padding_idx=0)\n",
      "  (lpe_linear): Linear(in_features=2, out_features=12, bias=True)\n",
      "  (lpe_linear3): Linear(in_features=30, out_features=12, bias=True)\n",
      "  (position): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (outp_logits): Linear(in_features=256, out_features=531, bias=True)\n",
      "  (decoderLayers): ModuleList(\n",
      "    (0): DecoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mask_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mem_att_sublayer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mem_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_mem_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): DecoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mask_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mem_att_sublayer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mem_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_mem_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): DecoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mask_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mem_att_sublayer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mem_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_mem_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): DecoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mask_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mem_att_sublayer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mem_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_mem_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): DecoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mask_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mem_att_sublayer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mem_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_mem_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (5): DecoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mask_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mem_att_sublayer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_mem_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_mem_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0): EncoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): EncoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): EncoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): EncoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): EncoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (5): EncoderLayer(\n",
      "      (self_attention_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_attention): MultiHeadAttention(\n",
      "        (linear_q): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_k): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (linear_v): Linear(in_features=256, out_features=252, bias=True)\n",
      "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (output_layer): Linear(in_features=252, out_features=256, bias=True)\n",
      "      )\n",
      "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (ffn_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForwardNetwork(\n",
      "        (layer1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (gelu): GELU()\n",
      "        (layer2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (graph_token): Embedding(11, 256)\n",
      "  (graph_token_virtual_distance): Embedding(1, 12)\n",
      "  (rbf): RBFLayer()\n",
      "  (rel_pos_3d_proj): Linear(in_features=256, out_features=12, bias=True)\n",
      ")\n",
      "total params: 12758351\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory /home/jovyan/g2gt_github/src/lightning_logs/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:433: UserWarning: ModelCheckpoint(save_last=True, save_top_k=None, monitor=None) is a redundant configuration. You can save the last checkpoint with ModelCheckpoint(save_top_k=None, monitor=None).\n",
      "  \"ModelCheckpoint(save_last=True, save_top_k=None, monitor=None) is a redundant configuration.\"\n",
      "args.resume_from_checkpoint /home/jovyan/g2gt_github/src/lightning_logs/checkpoints/last.ckpt\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Restoring states from the checkpoint file at /home/jovyan/g2gt_github/src/lightning_logs/checkpoints/last.ckpt\n",
      "Global seed set to 0\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All DDP processes registered. Starting ddp with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Restored all states from the checkpoint file at /home/jovyan/g2gt_github/src/lightning_logs/checkpoints/last.ckpt\n",
      "\n",
      "   | Name                         | Type               | Params\n",
      "---------------------------------------------------------------------\n",
      "0  | atom_encoder                 | Embedding          | 1.2 M \n",
      "1  | edge_encoder                 | Embedding          | 9.2 K \n",
      "2  | rel_pos_encoder              | Embedding          | 6.1 K \n",
      "3  | in_degree_encoder            | Embedding          | 131 K \n",
      "4  | out_degree_encoder           | Embedding          | 131 K \n",
      "5  | input_dropout                | Dropout            | 0     \n",
      "6  | input_dropout2d              | Dropout2d          | 0     \n",
      "7  | gelu                         | GELU               | 0     \n",
      "8  | atom_edge_encoder            | Embedding          | 139 K \n",
      "9  | centrality_encoder           | Embedding          | 600   \n",
      "10 | lpe_linear                   | Linear             | 36    \n",
      "11 | lpe_linear3                  | Linear             | 372   \n",
      "12 | position                     | PositionalEncoding | 0     \n",
      "13 | outp_logits                  | Linear             | 136 K \n",
      "14 | decoderLayers                | ModuleList         | 6.3 M \n",
      "15 | layers                       | ModuleList         | 4.7 M \n",
      "16 | graph_token                  | Embedding          | 2.8 K \n",
      "17 | graph_token_virtual_distance | Embedding          | 12    \n",
      "18 | rbf                          | RBFLayer           | 512   \n",
      "19 | rel_pos_3d_proj              | Linear             | 3.1 K \n",
      "---------------------------------------------------------------------\n",
      "12.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.8 M    Total params\n",
      "51.033    Total estimated model params size (MB)\n",
      "Validation sanity check: 0it [00:00, ?it/s]len(val_dataloader) 5000\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "Validation sanity check:   0%|                            | 0/2 [00:00<?, ?it/s]validation_epoch_end\n",
      "graph acc: 0.0\n",
      "valid accuracy: 0.9741935133934021\n",
      "Global seed set to 0                                                            \n",
      "len(train_dataloader) 8000\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "Epoch 154:   0%|   | 20/48000 [00:11<7:04:59,  1.88it/s, loss=0.0232, v_num=729]^C\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1046: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "! bash train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13986e99-8d9c-4586-af0e-dc555a95655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "! bash inference.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce55c3f-ef90-46be-b65a-43a497ff93f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
